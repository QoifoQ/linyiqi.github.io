---
permalink: /STAT3009/
title: "STAT3009 Recommender Systems"
---

> "*All models are wrong, but some are useful." — George E. P. Box*

## 📃 <span style="color:DarkSalmon"> Content </span>


---

## 💬 <span style="color:LightSalmon"> Announcement </span> 

---

- Sep 1, 2021: Welcome to STAT3XXX: Recommender Systems with Python.

## ℹ️ Administrative information

---

- ⏲️ **Lectures**: Add time here
- 👨‍🏫 **Instructor**: [Ben Dai](http://www.bendai.org)
- 👨‍💼 **TAs**:
- ⏳ **Office hours**:
- 📞 **Contact**:

## 🗓️ Schedule

---

[Weekly notes](https://www.notion.so/1ae83e07c8a94d1488a5c3533f17acd0)

## 🧾 Course Content

---

🖥️ **Description:**

Commercial sites such as search engines, advertisers and median (e.g., Netflix, Amazon), and financial institutions employ recommender systems for content recommendation, predicting customer behavior, compliance, or risk.

This course provides an overview of predictive models for recommender systems, including content-based collaborative algorithms, latent factor models, and deep learning models, as well as Python implementation, evaluation and metrics for recommender systems.

🔑 **Key words:**

In this course, students will learn about principles and algorithms for turning training data into effective automated predictions. We will cover:

- Python programming, recommender systems library
- Correlation-based collaborative filtering, latent factor models, neural collaborative filtering, deep learning models
- Recommender systems, link prediction, Top-K recommendation
- Tuning, bagging, ensemble in recommender systems

👌 **What you'll learn:**

- Understand principles behind recommender systems approaches such as correlation-based collaborative filtering, latent factor models, neural recommender systems
- Implement and analyze recommender systems to real applications by Python
- Choose and tune suitable models for different applications

🏗️ **Prerequisites:**

- STAT2005, STAT2006, STAT2102

## 💯 Grading

---

👨‍💻 **Coursework:**

- Homeworks (20%)

there will be three homeworks (plus a warmup which does not count towards your grade), centered around proving properties of statistical procedures. You are encouraged to use LaTeX to writeup your homeworks (here's a template), but this is not a requirement. You will receive one (1) bonus point for submitting a typed written assignment (e.g. LaTeX, Microsoft Word). We will accept scanned handwritten assignments but they will not receive the bonus point.

- Exam (20%)

open-book, open-notes. Problems will be like the homeworks, but simpler. You can use laptops as long as you turn off the wireless.

- Real application project (60%)

A full analysis provided in form of report and Jupter notebook. (1) An executable notebook containing the performed analysis on the data; (2) A technique report includes the (i) mathematical form and intuitive interpretation of your predictive models (ii) details about the data processing and hyper-parameters tuning. 

👨🏻‍🤝‍👨🏾 **Collaboration policy**: we admit you to form a group to finish your real application projects. The number of group members should be smaller or equal than 3. The contribution of each member should be clearly stated in the final report. You will receive one (1) bonus point if you work solo to the final project.

## 📋 Recommended Readings

---

1. Aggarwal, C. C. (2016). Recommender systems (Vol. 1). Cham: Springer International Publishing.
2. Zhang, S., Yao, L., Sun, A., & Tay, Y. (2019). Deep learning based recommender system: A survey and new perspectives. ACM Computing Surveys (CSUR), 52(1), 1-38.
3. Funk, S. (2006). Netflix update: Try this at home.
4. Chen, H., Li, X., & Huang, Z. (2005, June). Link prediction approach to collaborative filtering. In Proceedings of the 5th ACM/IEEE-CS Joint Conference on Digital Libraries (JCDL'05) (pp. 141-142). IEEE.
5. He, X., Liao, L., Zhang, H., Nie, L., Hu, X., & Chua, T. S. (2017, April). Neural collaborative filtering. In Proceedings of the 26th international conference on world wide web (pp. 173-182).
6. Dai, B., Wang, J., Shen, X., & Qu, A. (2019). Smooth neighborhood recommender systems. Journal of Machine Learning Research, 20.
7. Koren, Y., Bell, R., & Volinsky, C. (2009). Matrix factorization techniques for recommender systems. Computer, 42(8), 30-37.
8. Insight blog: [Explicit Matrix Factorization: ALS, SGD, and All That Jazz](https://blog.insightdatascience.com/explicit-matrix-factorization-als-sgd-and-all-that-jazz-b00e4d9b21ea)
9. Github: [Matrix Factorization for Recommender Systems](https://everdark.github.io/k9/notebooks/ml/matrix_factorization/matrix_factorization.nb.html)
10. Agarwal, D., & Chen, B. C. (2009, June). Regression-based latent factor models. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 19-28).
11. Deshpande, M., & Karypis, G. (2004). Item-based top-n recommendation algorithms. ACM Transactions on Information Systems (TOIS), 22(1), 143-177.
12. Dai, B., Shen, X., Wang, J., & Qu, A. (2019). Scalable Collaborative Ranking for Personalized Prediction. Journal of the American Statistical Association, 1-9.
13. Wang, S., Wang, Y., Tang, J., Shu, K., Ranganath, S., & Liu, H. (2017, April). What your images reveal: Exploiting visual contents for point-of-interest recommendation. In Proceedings of the 26th international conference on world wide web (pp. 391-400).
14. [Music artist Recommender System using Stochastic Gradient Descent | Machine Learning from Scratch (Part VII)](https://towardsdatascience.com/music-artist-recommender-system-using-stochastic-gradient-descent-machine-learning-from-scratch-5f2f1aae972c)
15. [Understanding matrix factorization for recommendation (part 3) - SVD for recommendation](http://nicolas-hug.com/blog/matrix_facto_3)
16. [Creating a Simple Recommender System in Python using Pandas](https://stackabuse.com/creating-a-simple-recommender-system-in-python-using-pandas/)
17. [khanhnamele's GitHub: MovieLens Recommendation Systems](https://github.com/khanhnamle1994/movielens)